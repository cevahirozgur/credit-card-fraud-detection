{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9120,"databundleVersionId":860599,"sourceType":"competition"},{"sourceId":50160,"databundleVersionId":7921029,"sourceType":"competition"},{"sourceId":666,"sourceType":"datasetVersion","datasetId":306},{"sourceId":1056,"sourceType":"datasetVersion","datasetId":531},{"sourceId":23498,"sourceType":"datasetVersion","datasetId":310},{"sourceId":552038,"sourceType":"datasetVersion","datasetId":263888},{"sourceId":1399887,"sourceType":"datasetVersion","datasetId":817870},{"sourceId":1660340,"sourceType":"datasetVersion","datasetId":982921},{"sourceId":4422779,"sourceType":"datasetVersion","datasetId":2590623},{"sourceId":8050363,"sourceType":"datasetVersion","datasetId":4541632},{"sourceId":16695845,"sourceType":"kernelVersion"}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-04-27T07:52:08.828882Z","iopub.execute_input":"2024-04-27T07:52:08.829172Z","iopub.status.idle":"2024-04-27T07:52:09.919464Z","shell.execute_reply.started":"2024-04-27T07:52:08.829147Z","shell.execute_reply":"2024-04-27T07:52:09.918515Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"data =pd.read_csv('/kaggle/input/creditcardfraud/creditcard.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-27T07:52:18.744971Z","iopub.execute_input":"2024-04-27T07:52:18.745444Z","iopub.status.idle":"2024-04-27T07:52:22.031629Z","shell.execute_reply.started":"2024-04-27T07:52:18.745416Z","shell.execute_reply":"2024-04-27T07:52:22.030732Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T07:52:23.244954Z","iopub.execute_input":"2024-04-27T07:52:23.245290Z","iopub.status.idle":"2024-04-27T07:52:23.285143Z","shell.execute_reply.started":"2024-04-27T07:52:23.245267Z","shell.execute_reply":"2024-04-27T07:52:23.284287Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   Time        V1        V2        V3        V4        V5        V6        V7  \\\n0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n\n         V8        V9  ...       V21       V22       V23       V24       V25  \\\n0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n\n        V26       V27       V28  Amount  Class  \n0 -0.189115  0.133558 -0.021053  149.62      0  \n1  0.125895 -0.008983  0.014724    2.69      0  \n2 -0.139097 -0.055353 -0.059752  378.66      0  \n3 -0.221929  0.062723  0.061458  123.50      0  \n4  0.502292  0.219422  0.215153   69.99      0  \n\n[5 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>...</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>149.62</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>...</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>2.69</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>...</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>378.66</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>...</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>123.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0</td>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>...</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>69.99</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 31 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"pd.options.display.max_columns = None","metadata":{"execution":{"iopub.status.busy":"2024-04-27T07:52:24.221548Z","iopub.execute_input":"2024-04-27T07:52:24.222111Z","iopub.status.idle":"2024-04-27T07:52:24.226103Z","shell.execute_reply.started":"2024-04-27T07:52:24.222080Z","shell.execute_reply":"2024-04-27T07:52:24.225180Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T07:52:25.284701Z","iopub.execute_input":"2024-04-27T07:52:25.285048Z","iopub.status.idle":"2024-04-27T07:52:25.313558Z","shell.execute_reply.started":"2024-04-27T07:52:25.285021Z","shell.execute_reply":"2024-04-27T07:52:25.312565Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   Time        V1        V2        V3        V4        V5        V6        V7  \\\n0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n\n         V8        V9       V10       V11       V12       V13       V14  \\\n0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n\n        V15       V16       V17       V18       V19       V20       V21  \\\n0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n\n        V22       V23       V24       V25       V26       V27       V28  \\\n0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n\n   Amount  Class  \n0  149.62      0  \n1    2.69      0  \n2  378.66      0  \n3  123.50      0  \n4   69.99      0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>V10</th>\n      <th>V11</th>\n      <th>V12</th>\n      <th>V13</th>\n      <th>V14</th>\n      <th>V15</th>\n      <th>V16</th>\n      <th>V17</th>\n      <th>V18</th>\n      <th>V19</th>\n      <th>V20</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>0.090794</td>\n      <td>-0.551600</td>\n      <td>-0.617801</td>\n      <td>-0.991390</td>\n      <td>-0.311169</td>\n      <td>1.468177</td>\n      <td>-0.470401</td>\n      <td>0.207971</td>\n      <td>0.025791</td>\n      <td>0.403993</td>\n      <td>0.251412</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>149.62</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>-0.166974</td>\n      <td>1.612727</td>\n      <td>1.065235</td>\n      <td>0.489095</td>\n      <td>-0.143772</td>\n      <td>0.635558</td>\n      <td>0.463917</td>\n      <td>-0.114805</td>\n      <td>-0.183361</td>\n      <td>-0.145783</td>\n      <td>-0.069083</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>2.69</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>0.207643</td>\n      <td>0.624501</td>\n      <td>0.066084</td>\n      <td>0.717293</td>\n      <td>-0.165946</td>\n      <td>2.345865</td>\n      <td>-2.890083</td>\n      <td>1.109969</td>\n      <td>-0.121359</td>\n      <td>-2.261857</td>\n      <td>0.524980</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>378.66</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>-0.054952</td>\n      <td>-0.226487</td>\n      <td>0.178228</td>\n      <td>0.507757</td>\n      <td>-0.287924</td>\n      <td>-0.631418</td>\n      <td>-1.059647</td>\n      <td>-0.684093</td>\n      <td>1.965775</td>\n      <td>-1.232622</td>\n      <td>-0.208038</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>123.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0</td>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>0.753074</td>\n      <td>-0.822843</td>\n      <td>0.538196</td>\n      <td>1.345852</td>\n      <td>-1.119670</td>\n      <td>0.175121</td>\n      <td>-0.451449</td>\n      <td>-0.237033</td>\n      <td>-0.038195</td>\n      <td>0.803487</td>\n      <td>0.408542</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>69.99</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.tail()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T07:52:26.159074Z","iopub.execute_input":"2024-04-27T07:52:26.159454Z","iopub.status.idle":"2024-04-27T07:52:26.189807Z","shell.execute_reply.started":"2024-04-27T07:52:26.159426Z","shell.execute_reply":"2024-04-27T07:52:26.189071Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"            Time         V1         V2        V3        V4        V5  \\\n284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n\n              V6        V7        V8        V9       V10       V11       V12  \\\n284802 -2.606837 -4.918215  7.305334  1.914428  4.356170 -1.593105  2.711941   \n284803  1.058415  0.024330  0.294869  0.584800 -0.975926 -0.150189  0.915802   \n284804  3.031260 -0.296827  0.708417  0.432454 -0.484782  0.411614  0.063119   \n284805  0.623708 -0.686180  0.679145  0.392087 -0.399126 -1.933849 -0.962886   \n284806 -0.649617  1.577006 -0.414650  0.486180 -0.915427 -1.040458 -0.031513   \n\n             V13       V14       V15       V16       V17       V18       V19  \\\n284802 -0.689256  4.626942 -0.924459  1.107641  1.991691  0.510632 -0.682920   \n284803  1.214756 -0.675143  1.164931 -0.711757 -0.025693 -1.221179 -1.545556   \n284804 -0.183699 -0.510602  1.329284  0.140716  0.313502  0.395652 -0.577252   \n284805 -1.042082  0.449624  1.962563 -0.608577  0.509928  1.113981  2.897849   \n284806 -0.188093 -0.084316  0.041333 -0.302620 -0.660377  0.167430 -0.256117   \n\n             V20       V21       V22       V23       V24       V25       V26  \\\n284802  1.475829  0.213454  0.111864  1.014480 -0.509348  1.436807  0.250034   \n284803  0.059616  0.214205  0.924384  0.012463 -1.016226 -0.606624 -0.395255   \n284804  0.001396  0.232045  0.578229 -0.037501  0.640134  0.265745 -0.087371   \n284805  0.127434  0.265245  0.800049 -0.163298  0.123205 -0.569159  0.546668   \n284806  0.382948  0.261057  0.643078  0.376777  0.008797 -0.473649 -0.818267   \n\n             V27       V28  Amount  Class  \n284802  0.943651  0.823731    0.77      0  \n284803  0.068472 -0.053527   24.79      0  \n284804  0.004455 -0.026561   67.88      0  \n284805  0.108821  0.104533   10.00      0  \n284806 -0.002415  0.013649  217.00      0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>V10</th>\n      <th>V11</th>\n      <th>V12</th>\n      <th>V13</th>\n      <th>V14</th>\n      <th>V15</th>\n      <th>V16</th>\n      <th>V17</th>\n      <th>V18</th>\n      <th>V19</th>\n      <th>V20</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>284802</th>\n      <td>172786.0</td>\n      <td>-11.881118</td>\n      <td>10.071785</td>\n      <td>-9.834783</td>\n      <td>-2.066656</td>\n      <td>-5.364473</td>\n      <td>-2.606837</td>\n      <td>-4.918215</td>\n      <td>7.305334</td>\n      <td>1.914428</td>\n      <td>4.356170</td>\n      <td>-1.593105</td>\n      <td>2.711941</td>\n      <td>-0.689256</td>\n      <td>4.626942</td>\n      <td>-0.924459</td>\n      <td>1.107641</td>\n      <td>1.991691</td>\n      <td>0.510632</td>\n      <td>-0.682920</td>\n      <td>1.475829</td>\n      <td>0.213454</td>\n      <td>0.111864</td>\n      <td>1.014480</td>\n      <td>-0.509348</td>\n      <td>1.436807</td>\n      <td>0.250034</td>\n      <td>0.943651</td>\n      <td>0.823731</td>\n      <td>0.77</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>284803</th>\n      <td>172787.0</td>\n      <td>-0.732789</td>\n      <td>-0.055080</td>\n      <td>2.035030</td>\n      <td>-0.738589</td>\n      <td>0.868229</td>\n      <td>1.058415</td>\n      <td>0.024330</td>\n      <td>0.294869</td>\n      <td>0.584800</td>\n      <td>-0.975926</td>\n      <td>-0.150189</td>\n      <td>0.915802</td>\n      <td>1.214756</td>\n      <td>-0.675143</td>\n      <td>1.164931</td>\n      <td>-0.711757</td>\n      <td>-0.025693</td>\n      <td>-1.221179</td>\n      <td>-1.545556</td>\n      <td>0.059616</td>\n      <td>0.214205</td>\n      <td>0.924384</td>\n      <td>0.012463</td>\n      <td>-1.016226</td>\n      <td>-0.606624</td>\n      <td>-0.395255</td>\n      <td>0.068472</td>\n      <td>-0.053527</td>\n      <td>24.79</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>284804</th>\n      <td>172788.0</td>\n      <td>1.919565</td>\n      <td>-0.301254</td>\n      <td>-3.249640</td>\n      <td>-0.557828</td>\n      <td>2.630515</td>\n      <td>3.031260</td>\n      <td>-0.296827</td>\n      <td>0.708417</td>\n      <td>0.432454</td>\n      <td>-0.484782</td>\n      <td>0.411614</td>\n      <td>0.063119</td>\n      <td>-0.183699</td>\n      <td>-0.510602</td>\n      <td>1.329284</td>\n      <td>0.140716</td>\n      <td>0.313502</td>\n      <td>0.395652</td>\n      <td>-0.577252</td>\n      <td>0.001396</td>\n      <td>0.232045</td>\n      <td>0.578229</td>\n      <td>-0.037501</td>\n      <td>0.640134</td>\n      <td>0.265745</td>\n      <td>-0.087371</td>\n      <td>0.004455</td>\n      <td>-0.026561</td>\n      <td>67.88</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>284805</th>\n      <td>172788.0</td>\n      <td>-0.240440</td>\n      <td>0.530483</td>\n      <td>0.702510</td>\n      <td>0.689799</td>\n      <td>-0.377961</td>\n      <td>0.623708</td>\n      <td>-0.686180</td>\n      <td>0.679145</td>\n      <td>0.392087</td>\n      <td>-0.399126</td>\n      <td>-1.933849</td>\n      <td>-0.962886</td>\n      <td>-1.042082</td>\n      <td>0.449624</td>\n      <td>1.962563</td>\n      <td>-0.608577</td>\n      <td>0.509928</td>\n      <td>1.113981</td>\n      <td>2.897849</td>\n      <td>0.127434</td>\n      <td>0.265245</td>\n      <td>0.800049</td>\n      <td>-0.163298</td>\n      <td>0.123205</td>\n      <td>-0.569159</td>\n      <td>0.546668</td>\n      <td>0.108821</td>\n      <td>0.104533</td>\n      <td>10.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>284806</th>\n      <td>172792.0</td>\n      <td>-0.533413</td>\n      <td>-0.189733</td>\n      <td>0.703337</td>\n      <td>-0.506271</td>\n      <td>-0.012546</td>\n      <td>-0.649617</td>\n      <td>1.577006</td>\n      <td>-0.414650</td>\n      <td>0.486180</td>\n      <td>-0.915427</td>\n      <td>-1.040458</td>\n      <td>-0.031513</td>\n      <td>-0.188093</td>\n      <td>-0.084316</td>\n      <td>0.041333</td>\n      <td>-0.302620</td>\n      <td>-0.660377</td>\n      <td>0.167430</td>\n      <td>-0.256117</td>\n      <td>0.382948</td>\n      <td>0.261057</td>\n      <td>0.643078</td>\n      <td>0.376777</td>\n      <td>0.008797</td>\n      <td>-0.473649</td>\n      <td>-0.818267</td>\n      <td>-0.002415</td>\n      <td>0.013649</td>\n      <td>217.00</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-27T07:52:26.959506Z","iopub.execute_input":"2024-04-27T07:52:26.959826Z","iopub.status.idle":"2024-04-27T07:52:26.966284Z","shell.execute_reply.started":"2024-04-27T07:52:26.959784Z","shell.execute_reply":"2024-04-27T07:52:26.965320Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(284807, 31)"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Number of columns: {}\".format(data.shape[1]))\nprint(\"Number of rows: {}\".format(data.shape[0]))","metadata":{"execution":{"iopub.status.busy":"2024-04-27T07:52:27.699935Z","iopub.execute_input":"2024-04-27T07:52:27.700568Z","iopub.status.idle":"2024-04-27T07:52:27.705581Z","shell.execute_reply.started":"2024-04-27T07:52:27.700537Z","shell.execute_reply":"2024-04-27T07:52:27.704642Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Number of columns: 31\nNumber of rows: 284807\n","output_type":"stream"}]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T07:52:28.445780Z","iopub.execute_input":"2024-04-27T07:52:28.446110Z","iopub.status.idle":"2024-04-27T07:52:28.486601Z","shell.execute_reply.started":"2024-04-27T07:52:28.446084Z","shell.execute_reply":"2024-04-27T07:52:28.485681Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 284807 entries, 0 to 284806\nData columns (total 31 columns):\n #   Column  Non-Null Count   Dtype  \n---  ------  --------------   -----  \n 0   Time    284807 non-null  float64\n 1   V1      284807 non-null  float64\n 2   V2      284807 non-null  float64\n 3   V3      284807 non-null  float64\n 4   V4      284807 non-null  float64\n 5   V5      284807 non-null  float64\n 6   V6      284807 non-null  float64\n 7   V7      284807 non-null  float64\n 8   V8      284807 non-null  float64\n 9   V9      284807 non-null  float64\n 10  V10     284807 non-null  float64\n 11  V11     284807 non-null  float64\n 12  V12     284807 non-null  float64\n 13  V13     284807 non-null  float64\n 14  V14     284807 non-null  float64\n 15  V15     284807 non-null  float64\n 16  V16     284807 non-null  float64\n 17  V17     284807 non-null  float64\n 18  V18     284807 non-null  float64\n 19  V19     284807 non-null  float64\n 20  V20     284807 non-null  float64\n 21  V21     284807 non-null  float64\n 22  V22     284807 non-null  float64\n 23  V23     284807 non-null  float64\n 24  V24     284807 non-null  float64\n 25  V25     284807 non-null  float64\n 26  V26     284807 non-null  float64\n 27  V27     284807 non-null  float64\n 28  V28     284807 non-null  float64\n 29  Amount  284807 non-null  float64\n 30  Class   284807 non-null  int64  \ndtypes: float64(30), int64(1)\nmemory usage: 67.4 MB\n","output_type":"stream"}]},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T07:52:29.144545Z","iopub.execute_input":"2024-04-27T07:52:29.145184Z","iopub.status.idle":"2024-04-27T07:52:29.165666Z","shell.execute_reply.started":"2024-04-27T07:52:29.145154Z","shell.execute_reply":"2024-04-27T07:52:29.164868Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Time      0\nV1        0\nV2        0\nV3        0\nV4        0\nV5        0\nV6        0\nV7        0\nV8        0\nV9        0\nV10       0\nV11       0\nV12       0\nV13       0\nV14       0\nV15       0\nV16       0\nV17       0\nV18       0\nV19       0\nV20       0\nV21       0\nV22       0\nV23       0\nV24       0\nV25       0\nV26       0\nV27       0\nV28       0\nAmount    0\nClass     0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler","metadata":{"execution":{"iopub.status.busy":"2024-04-27T07:52:29.844427Z","iopub.execute_input":"2024-04-27T07:52:29.845263Z","iopub.status.idle":"2024-04-27T07:52:30.290722Z","shell.execute_reply.started":"2024-04-27T07:52:29.845233Z","shell.execute_reply":"2024-04-27T07:52:30.289731Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"sc = StandardScaler()\ndata['Amount'] = sc.fit_transform(pd.DataFrame(data['Amount']))","metadata":{"execution":{"iopub.status.busy":"2024-04-27T07:52:31.745909Z","iopub.execute_input":"2024-04-27T07:52:31.746564Z","iopub.status.idle":"2024-04-27T07:52:31.758204Z","shell.execute_reply.started":"2024-04-27T07:52:31.746531Z","shell.execute_reply":"2024-04-27T07:52:31.756991Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T07:52:32.644964Z","iopub.execute_input":"2024-04-27T07:52:32.645886Z","iopub.status.idle":"2024-04-27T07:52:32.677328Z","shell.execute_reply.started":"2024-04-27T07:52:32.645847Z","shell.execute_reply":"2024-04-27T07:52:32.676399Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"   Time        V1        V2        V3        V4        V5        V6        V7  \\\n0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n\n         V8        V9       V10       V11       V12       V13       V14  \\\n0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n\n        V15       V16       V17       V18       V19       V20       V21  \\\n0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n\n        V22       V23       V24       V25       V26       V27       V28  \\\n0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n\n     Amount  Class  \n0  0.244964      0  \n1 -0.342475      0  \n2  1.160686      0  \n3  0.140534      0  \n4 -0.073403      0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>V10</th>\n      <th>V11</th>\n      <th>V12</th>\n      <th>V13</th>\n      <th>V14</th>\n      <th>V15</th>\n      <th>V16</th>\n      <th>V17</th>\n      <th>V18</th>\n      <th>V19</th>\n      <th>V20</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>0.090794</td>\n      <td>-0.551600</td>\n      <td>-0.617801</td>\n      <td>-0.991390</td>\n      <td>-0.311169</td>\n      <td>1.468177</td>\n      <td>-0.470401</td>\n      <td>0.207971</td>\n      <td>0.025791</td>\n      <td>0.403993</td>\n      <td>0.251412</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>0.244964</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>-0.166974</td>\n      <td>1.612727</td>\n      <td>1.065235</td>\n      <td>0.489095</td>\n      <td>-0.143772</td>\n      <td>0.635558</td>\n      <td>0.463917</td>\n      <td>-0.114805</td>\n      <td>-0.183361</td>\n      <td>-0.145783</td>\n      <td>-0.069083</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>-0.342475</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>0.207643</td>\n      <td>0.624501</td>\n      <td>0.066084</td>\n      <td>0.717293</td>\n      <td>-0.165946</td>\n      <td>2.345865</td>\n      <td>-2.890083</td>\n      <td>1.109969</td>\n      <td>-0.121359</td>\n      <td>-2.261857</td>\n      <td>0.524980</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>1.160686</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>-0.054952</td>\n      <td>-0.226487</td>\n      <td>0.178228</td>\n      <td>0.507757</td>\n      <td>-0.287924</td>\n      <td>-0.631418</td>\n      <td>-1.059647</td>\n      <td>-0.684093</td>\n      <td>1.965775</td>\n      <td>-1.232622</td>\n      <td>-0.208038</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>0.140534</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0</td>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>0.753074</td>\n      <td>-0.822843</td>\n      <td>0.538196</td>\n      <td>1.345852</td>\n      <td>-1.119670</td>\n      <td>0.175121</td>\n      <td>-0.451449</td>\n      <td>-0.237033</td>\n      <td>-0.038195</td>\n      <td>0.803487</td>\n      <td>0.408542</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>-0.073403</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data = data.drop(['Time'], axis =1)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T07:52:33.409800Z","iopub.execute_input":"2024-04-27T07:52:33.410132Z","iopub.status.idle":"2024-04-27T07:52:33.439212Z","shell.execute_reply.started":"2024-04-27T07:52:33.410106Z","shell.execute_reply":"2024-04-27T07:52:33.438143Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T07:52:34.220802Z","iopub.execute_input":"2024-04-27T07:52:34.221710Z","iopub.status.idle":"2024-04-27T07:52:34.254262Z","shell.execute_reply.started":"2024-04-27T07:52:34.221678Z","shell.execute_reply":"2024-04-27T07:52:34.253285Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"         V1        V2        V3        V4        V5        V6        V7  \\\n0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n\n         V8        V9       V10       V11       V12       V13       V14  \\\n0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n\n        V15       V16       V17       V18       V19       V20       V21  \\\n0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n\n        V22       V23       V24       V25       V26       V27       V28  \\\n0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n\n     Amount  Class  \n0  0.244964      0  \n1 -0.342475      0  \n2  1.160686      0  \n3  0.140534      0  \n4 -0.073403      0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>V10</th>\n      <th>V11</th>\n      <th>V12</th>\n      <th>V13</th>\n      <th>V14</th>\n      <th>V15</th>\n      <th>V16</th>\n      <th>V17</th>\n      <th>V18</th>\n      <th>V19</th>\n      <th>V20</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>0.090794</td>\n      <td>-0.551600</td>\n      <td>-0.617801</td>\n      <td>-0.991390</td>\n      <td>-0.311169</td>\n      <td>1.468177</td>\n      <td>-0.470401</td>\n      <td>0.207971</td>\n      <td>0.025791</td>\n      <td>0.403993</td>\n      <td>0.251412</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>0.244964</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>-0.166974</td>\n      <td>1.612727</td>\n      <td>1.065235</td>\n      <td>0.489095</td>\n      <td>-0.143772</td>\n      <td>0.635558</td>\n      <td>0.463917</td>\n      <td>-0.114805</td>\n      <td>-0.183361</td>\n      <td>-0.145783</td>\n      <td>-0.069083</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>-0.342475</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>0.207643</td>\n      <td>0.624501</td>\n      <td>0.066084</td>\n      <td>0.717293</td>\n      <td>-0.165946</td>\n      <td>2.345865</td>\n      <td>-2.890083</td>\n      <td>1.109969</td>\n      <td>-0.121359</td>\n      <td>-2.261857</td>\n      <td>0.524980</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>1.160686</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>-0.054952</td>\n      <td>-0.226487</td>\n      <td>0.178228</td>\n      <td>0.507757</td>\n      <td>-0.287924</td>\n      <td>-0.631418</td>\n      <td>-1.059647</td>\n      <td>-0.684093</td>\n      <td>1.965775</td>\n      <td>-1.232622</td>\n      <td>-0.208038</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>0.140534</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>0.753074</td>\n      <td>-0.822843</td>\n      <td>0.538196</td>\n      <td>1.345852</td>\n      <td>-1.119670</td>\n      <td>0.175121</td>\n      <td>-0.451449</td>\n      <td>-0.237033</td>\n      <td>-0.038195</td>\n      <td>0.803487</td>\n      <td>0.408542</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>-0.073403</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.duplicated().any()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T07:52:34.871116Z","iopub.execute_input":"2024-04-27T07:52:34.871458Z","iopub.status.idle":"2024-04-27T07:52:35.457433Z","shell.execute_reply.started":"2024-04-27T07:52:34.871431Z","shell.execute_reply":"2024-04-27T07:52:35.456426Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"data = data.drop_duplicates()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T07:52:35.574331Z","iopub.execute_input":"2024-04-27T07:52:35.574630Z","iopub.status.idle":"2024-04-27T07:52:36.199875Z","shell.execute_reply.started":"2024-04-27T07:52:35.574605Z","shell.execute_reply":"2024-04-27T07:52:36.199055Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-27T07:52:36.306595Z","iopub.execute_input":"2024-04-27T07:52:36.306918Z","iopub.status.idle":"2024-04-27T07:52:36.312918Z","shell.execute_reply.started":"2024-04-27T07:52:36.306886Z","shell.execute_reply":"2024-04-27T07:52:36.312018Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(275663, 30)"},"metadata":{}}]},{"cell_type":"code","source":"data['Class'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T07:52:37.318326Z","iopub.execute_input":"2024-04-27T07:52:37.319047Z","iopub.status.idle":"2024-04-27T07:52:37.330456Z","shell.execute_reply.started":"2024-04-27T07:52:37.318996Z","shell.execute_reply":"2024-04-27T07:52:37.329567Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"Class\n0    275190\n1       473\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')","metadata":{"execution":{"iopub.status.busy":"2024-04-27T07:52:38.168667Z","iopub.execute_input":"2024-04-27T07:52:38.168982Z","iopub.status.idle":"2024-04-27T07:52:38.404172Z","shell.execute_reply.started":"2024-04-27T07:52:38.168957Z","shell.execute_reply":"2024-04-27T07:52:38.403390Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"sns.countplot(data['Class'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T07:52:38.950840Z","iopub.execute_input":"2024-04-27T07:52:38.951710Z","iopub.status.idle":"2024-04-27T07:52:39.178977Z","shell.execute_reply.started":"2024-04-27T07:52:38.951676Z","shell.execute_reply":"2024-04-27T07:52:39.177902Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAlkAAAGdCAYAAAAhaWZ4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAn70lEQVR4nO3da1BUZ57H8V9DN8pFaLwwQlpBAozZlYCZMVqJVaJmImOoSUxS0dFUXFFmZ71UqrKZrWxuoxmZyBinnERdUxF3pJKNGneoeEHNesnUGKwyiUsUdEWCRhBdYEPjclFp6H2R4qztbQjw2LR8P1VU7HMeDn/Ii/7WOYeDzev1egUAAIBeFeTvAQAAAO5GRBYAAIABRBYAAIABRBYAAIABRBYAAIABRBYAAIABRBYAAIABRBYAAIABRBYAAIABRBYAAIABdn8PAKmhoUEej8ffYwAAgC6w2+2Kjo7+6+vuwCz4Kzwej9ra2vw9BgAA6EVcLgQAADCAyAIAADCAyAIAADCAyAIAADCAyAIAADCAyAIAADCAyAIAADCAyAIAADCAyAIAADCAyAIAADCAyAIAADCAyAIAADCAyAIAADCAyAIAADDA7u8BcHe48KsF/h4BABAAYldu8PcIdwxnsgAAAAwgsgAAAAwgsgAAAAwgsgAAAAwgsgAAAAwgsgAAAAwgsgAAAAwgsgAAAAwgsgAAAAwgsgAAAAwgsgAAAAwgsgAAAAwgsgAAAAwgsgAAAAwgsgAAAAwgsgAAAAwgsgAAAAwgsgAAAAwgsgAAAAwgsgAAAAwgsgAAAAwgsgAAAAwgsgAAAAwgsgAAAAwgsgAAAAwgsgAAAAwgsgAAAAwgsgAAAAyw+3uAaxUWFurIkSM6f/68QkJClJKSomeffVZxcXHWmqVLl+rEiRM+n/fII4/oF7/4hfW6vr5e7733nsrKyjRw4EBNmjRJs2fPVnBwsLWmrKxMBQUFqqqq0pAhQ/TUU08pIyPD57h79uzRjh075Ha7FR8fr+zsbCUlJVn7r169qoKCAhUXF6utrU1paWlasGCBnE5n7/5gAABAwOlTkXXixAlNmzZN9957r9rb2/Xhhx9q+fLl+v3vf6+BAwda66ZOnaqZM2dar0NCQqx/d3R06M0335TT6dTy5cvV0NCgNWvWKDg4WLNnz5Yk1dbWasWKFfrJT36iJUuWqLS0VOvXr5fT6VR6erokqbi4WAUFBcrJyVFycrJ27dql3NxcrV69WlFRUZKkTZs26ejRo3rhhRcUFham/Px8rVq1Sr/5zW/uwE8LAAD0ZX3qcuErr7yijIwMjRgxQgkJCVq0aJHq6+tVWVnps27AgAFyOp3WR1hYmLXvq6++UnV1tZYsWaKEhASNHTtWM2fO1N69e+XxeCRJn3zyiWJiYvTcc8/J5XIpMzNTEyZM0K5du6zj7Ny5U1OnTtXkyZPlcrmUk5OjkJAQHTx4UJLU0tKiAwcOaO7cuRozZowSExO1cOFCnTp1SuXl5XfgpwUAAPqyPhVZ12tpaZEkRURE+Gz/y1/+ovnz5+sf//Ef9W//9m+6cuWKta+8vFwjR470uWSXnp6u1tZWVVVVSZJOnz6t1NRUn2OmpaVZceTxeFRZWemzJigoSKmpqdaayspKtbe3+6y55557NHTo0FtGVltbm1paWqyP1tZWa5/NZgvoDwAAusLf71d38j2vT10uvFZHR4f++Mc/6oc//KFGjhxpbZ84caKGDh2qwYMH65tvvtEHH3ygmpoavfjii5Ikt9t9wz1RnZf33G639d/ObdeuaW1t1dWrV9XU1KSOjo4bjuN0OlVTU2Mdw263Kzw8/IbjdH6d6xUWFmrbtm3W61GjRikvL0/Dhg3r0s+kL6vx9wAAgIAQGxvr7xHumD4bWfn5+aqqqtIbb7zhs/2RRx6x/j1y5EhFR0frjTfe0MWLFzV8+PA7Peb3MmPGDGVlZVmvO2u4rq7OupQJAMDd7MKFC/4eocfsdnuXTpD0ycjKz8/X0aNHtWzZMg0ZMuS2azt/268zspxOpyoqKnzWNDY2SpJ1ZsrpdFrbrl0TGhqqkJAQRUZGKigo6IYzUteeJXM6nfJ4PGpubvY5m9XY2HjL3y50OBxyOBw33ef1em/7fQIAcDfoT+93feqeLK/Xq/z8fB05ckSvv/66YmJi/urnnD17VpIUHR0tSUpJSdG5c+d8IurYsWMKDQ2Vy+WSJCUnJ+v48eM+xzl27JhSUlIkfVeoiYmJKi0ttfZ3dHSotLTUWpOYmKjg4GCf49TU1Ki+vt5aAwAA+q8+FVn5+fn6y1/+oueff16hoaFyu91yu926evWqpO/OVm3btk2VlZWqra3VF198obVr1+q+++5TfHy8pO9uYHe5XFqzZo3Onj2rkpISbd68WdOmTbPOIj366KOqra3V+++/r/Pnz2vv3r06fPiwHnvsMWuWrKws7d+/X59++qmqq6u1YcMGXblyxXqWVlhYmKZMmaKCggKVlpaqsrJS69atU0pKCpEFAABk8/ah83bPPPPMTbcvXLhQGRkZqq+v1zvvvKOqqipduXJFQ4YM0YMPPqgnn3zS5zEOdXV12rBhg8rKyjRgwABNmjRJc+bMueFhpJs2bVJ1dfVtH0a6fft2ud1uJSQkaN68eUpOTrb2dz6M9LPPPpPH4+n2w0jr6urU1tb2vT6nr7nwqwX+HgEAEABiV27w9wg95nA4unRPVp+KrP6KyAIA9Bf9KbL61OVCAACAuwWRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYACRBQAAYIDd3wNcq7CwUEeOHNH58+cVEhKilJQUPfvss4qLi7PWXL16VQUFBSouLlZbW5vS0tK0YMECOZ1Oa019fb3ee+89lZWVaeDAgZo0aZJmz56t4OBga01ZWZkKCgpUVVWlIUOG6KmnnlJGRobPPHv27NGOHTvkdrsVHx+v7OxsJSUlfa9ZAABA/9SnzmSdOHFC06ZNU25url599VW1t7dr+fLlunz5srVm06ZN+vLLL/XCCy9o2bJlamho0KpVq6z9HR0devPNN+XxeLR8+XItWrRIn376qbZs2WKtqa2t1YoVK/S3f/u3+t3vfqfHHntM69evV0lJibWmuLhYBQUFevrpp5WXl6f4+Hjl5uaqsbGxy7MAAID+q09F1iuvvKKMjAyNGDFCCQkJWrRokerr61VZWSlJamlp0YEDBzR37lyNGTNGiYmJWrhwoU6dOqXy8nJJ0ldffaXq6motWbJECQkJGjt2rGbOnKm9e/fK4/FIkj755BPFxMToueeek8vlUmZmpiZMmKBdu3ZZs+zcuVNTp07V5MmT5XK5lJOTo5CQEB08eLDLswAAgP6rT0XW9VpaWiRJERERkqTKykq1t7crNTXVWnPPPfdo6NChVtiUl5dr5MiRPpfs0tPT1draqqqqKknS6dOnfY4hSWlpadYxPB6PKisrfdYEBQUpNTXVWtOVWa7X1tamlpYW66O1tdXaZ7PZAvoDAICu8Pf71Z18z+tT92Rdq6OjQ3/84x/1wx/+UCNHjpQkud1u2e12hYeH+6yNioqS2+221lx/T1RUVJS1r/O/nduuXdPa2qqrV6+qqalJHR0dNxzH6XSqpqamy7Ncr7CwUNu2bbNejxo1Snl5eRo2bNhtfxaBoMbfAwAAAkJsbKy/R7hj+mxk5efnq6qqSm+88Ya/R+k1M2bMUFZWlvW6s4br6uqsS5kAANzNLly44O8Resxut3fpBEmfjKz8/HwdPXpUy5Yt05AhQ6ztTqdTHo9Hzc3NPmeQGhsbrbNOTqdTFRUVPsfrvFn92jXX3sDeuSY0NFQhISGKjIxUUFDQDWekrj1L1pVZrudwOORwOG66z+v13nQ7AAB3k/70ften7snyer3Kz8/XkSNH9PrrrysmJsZnf2JiooKDg3X8+HFrW01Njerr65WSkiJJSklJ0blz53wi6tixYwoNDZXL5ZIkJScn+xyjc03nMex2uxITE1VaWmrt7+joUGlpqbWmK7MAAID+q0+dycrPz9ehQ4f0T//0TwoNDbXOJIWFhSkkJERhYWGaMmWKCgoKFBERobCwMG3cuFEpKSlW2KSlpcnlcmnNmjWaM2eO3G63Nm/erGnTpllnkR599FHt3btX77//viZPnqzS0lIdPnxYL730kjVLVlaW1q5dq8TERCUlJamoqEhXrlyxnqXVlVkAAED/ZfP2ofN2zzzzzE23L1y40IqbzgeAfvbZZ/J4PDd9AGhdXZ02bNigsrIyDRgwQJMmTdKcOXNueBjppk2bVF1dfduHkW7fvl1ut1sJCQmaN2+ekpOTrf1dmaUr6urq1NbW9r0+p6+58KsF/h4BABAAYldu8PcIPeZwOLp0T1afiqz+isgCAPQX/Smy+tQ9WQAAAHcLIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMAAIgsAAMCAbkfWn//8Z9XW1t5yf21trf785z939/AAAAABrduRtW7dOpWXl99yf0VFhdatW9fdwwMAAAQ0Y5cLL1++rODgYFOHBwAA6NPs32fxN998o7Nnz1qvT548qfb29hvWNTc36z/+4z8UGxvb4wEBAAAC0feKrCNHjmjbtm3W63379mnfvn03XRsWFqbFixf3bDoAAIAA9b0i65FHHtGPfvQjeb1evfzyy3rmmWc0duzYG9YNHDhQP/jBD7hcCAAA+q3vFVnR0dGKjo6WJP3617/WPffco6ioKCODAQAABLLvFVnX+pu/+ZvenAMAAOCu0u3IkqSSkhIdOHBAtbW1am5ultfr9dlvs9n0zjvv9GhAAACAQNTtyNq+fbs++OADOZ1O3XvvvRo5cmRvzgUAABDQuh1ZRUVFGjNmjP75n/9ZdnuPTogBAADcdbpdR83NzZowYUKvBtaJEye0fft2nTlzRg0NDXrxxRf14IMPWvvXrl17w5/qSUtL0yuvvGK9bmpq0saNG/Xll1/KZrNp/PjxmjdvngYOHGit+eabb5Sfn6+vv/5akZGRyszM1OOPP+5z3MOHD2vLli2qq6vT8OHDNWfOHD3wwAPWfq/Xq61bt2r//v1qbm7W6NGjtWDBAp4NBgAAJPUgspKSklRTU9Obs+jKlStKSEjQlClT9NZbb910TXp6uhYuXGi9vj7y3n77bTU0NOjVV19Ve3u71q1bp3fffVfPP/+8JKmlpUXLly9XamqqcnJydO7cOf3Lv/yLwsPD9cgjj0iSTp06pT/84Q+aPXu2HnjgAR06dEgrV65UXl6edVn0448/1u7du7Vo0SLFxMRoy5Ytys3N1e9//3uFhIT06s8FAAAEnm7/WZ358+fryJEjOnToUK8NM3bsWM2aNcvn7NX17Ha7nE6n9REREWHtq66uVklJiX75y18qOTlZo0ePVnZ2toqLi/Xtt99Kkg4dOiSPx6OFCxdqxIgRevjhh/XTn/5UO3futI5TVFSk9PR0/exnP5PL5dKsWbOUmJioPXv2SPruLFZRUZGefPJJjRs3TvHx8Vq8eLEaGhr0+eef99rPAwAABK5un8lavXq12tvb9c477+i9997TkCFDFBTk22w2m00rV67s8ZDXOnHihBYsWKDw8HCNGTNGs2bN0qBBgyRJ5eXlCg8P17333mutT01Nlc1mU0VFhR588EGVl5frvvvu8zkDlpaWpo8//lhNTU2KiIhQeXm5srKyfL5uWlqaFVC1tbVyu926//77rf1hYWFKSkpSeXm5Hn744ZvO3tbWpra2Nuu1zWZTaGio9W8AAO52/en9rtuRFRERoUGDBt3Re5DS09M1fvx4xcTE6OLFi/rwww/129/+Vrm5uQoKCpLb7VZkZKTP5wQHBysiIkJut1uS5Ha7FRMT47PG6XRa+zrXXv+Q1aioKJ9jdG671ZqbKSws9PmzRKNGjVJeXp6GDRvWxZ9A39W7F44BAHer/nTvcrcja+nSpb04Rtdce4Zo5MiRio+P15IlS1RWVqbU1NQ7Ps/3NWPGDJ8zZJ01X1dXJ4/H46+xAAC4Yy5cuODvEXrMbrd36QRJQD974Qc/+IEGDRqkixcvKjU1VU6nU5cuXfJZ097erqamJutsldPpvOFsU+fra9c0Njb6rGlsbPTZ37mt888Mdb5OSEi45bwOh0MOh+Om+65/kCsAAHej/vR+1+3IOnHiRJfWmfzzO//zP/+jpqYmK3RSUlLU3NysyspKJSYmSpJKS0vl9XqVlJRkrfnwww/l8Xis+7KOHTumuLg46yb6lJQUHT9+XI899pj1tY4dO6bk5GRJUkxMjJxOp44fP25FVUtLiyoqKvToo48a+34BAEDg6HZkLVu2rEvrtmzZ0uVjXr58WRcvXrRe19bW6uzZs4qIiFBERIQ++ugjjR8/Xk6nU//93/+t999/X8OHD1daWpokyeVyKT09Xe+++65ycnLk8Xi0ceNGPfTQQxo8eLAkaeLEifroo4+0fv16Pf7446qqqtLu3bs1d+5c6+tOnz5dS5cu1Y4dO/TAAw/os88+09dff61f/OIXkr67zDd9+nT96U9/UmxsrGJiYrR582ZFR0dr3LhxXf5+AQDA3cvm7eZ5u5udyero6FBtba3279+vjo4OzZkzR2PGjOnyMcvKym4ab5MmTVJOTo5WrlypM2fOqLm5WYMHD9b999+vmTNnWpfvpO8eRpqfn+/zMNLs7OxbPox00KBByszM1BNPPOHzNQ8fPqzNmzerrq5OsbGxt3wY6b59+9TS0qLRo0dr/vz5iouL6/L326murs7ntw4D0YVfLfD3CACAABC7coO/R+gxh8PRpXuyuh1Zt9PR0aFf//rXGjNmjGbOnNnbh7/rEFkAgP6iP0VWtx9GetuDBgXpoYce0oEDB0wcHgAAoM8zElnSd5ftmpubTR0eAACgT+v2je/19fU33d7c3KyTJ09q+/btuu+++7o9GAAAQCDrdmQtWrTotvuTk5OVk5PT3cMDAAAEtG5H1j/8wz/csM1msyk8PFzDhw+Xy+Xq0WAAAACBrNuRlZGR0YtjAAAA3F165c/qVFdXq66uTpI0bNgwzmIBAIB+r0eR9fnnn6ugoEC1tbU+22NiYjR37lz9+Mc/7tFwAAAAgarbkXX06FGtWrVKw4YN089//nPr7FV1dbX279+vt956Sy+99JLS09N7a1YAAICA0e3I+vd//3fFx8dr2bJlPn+y5sc//rEyMzP1+uuv66OPPiKyAABAv9Tth5GeO3dOkyZN8gmsTgMHDlRGRobOnTvXo+EAAAACVbcjy+FwqKmp6Zb7m5qa5HA4unt4AACAgNbtyBozZoyKiopUXl5+w77Tp09r9+7dSk1N7dFwAAAAgarb92Q9++yzeuWVV/Taa68pKSlJcXFxkqSamhpVVFQoKipKc+bM6bVBAQAAAkm3IysmJkZvvfWWCgsLVVJSouLiYknfPSdr+vTpeuKJJxQVFdVrgwIAAASSbkdWe3u7HA6H/u7v/u6m+1taWtTe3q7g4ODufgkAAICA1e17sv71X/9Vr7322i33v/baayooKOju4QEAAAJatyOrpKRE48ePv+X+CRMm6D//8z+7e3gAAICA1u3Iamho0ODBg2+5Pzo6Wt9++213Dw8AABDQuh1ZERERqqmpueX+8+fPKzQ0tLuHBwAACGjdjqz09HTt27dPZ86cuWFfZWWl9u3bp7Fjx/ZoOAAAgEDV7d8unDlzpkpKSvTyyy/rRz/6kUaMGCFJqqqq0pdffqnIyEjNnDmz1wYFAAAIJN2OrMGDB2vFihX64IMP9MUXX+jzzz+XJIWGhmrixIn6+c9/ftt7tgAAAO5m3Y4s6bub2xcvXiyv16tLly5JkiIjI2Wz2XplOAAAgEDVo8jqZLPZeLo7AADANbp94zsAAABujcgCAAAwgMgCAAAwgMgCAAAwgMgCAAAwgMgCAAAwgMgCAAAwgMgCAAAwgMgCAAAwgMgCAAAwgMgCAAAwgMgCAAAwgMgCAAAwgMgCAAAwgMgCAAAwgMgCAAAwgMgCAAAwgMgCAAAwgMgCAAAwgMgCAAAwgMgCAAAwgMgCAAAwgMgCAAAwgMgCAAAwgMgCAAAwgMgCAAAwgMgCAAAwwO7vAa514sQJbd++XWfOnFFDQ4NefPFFPfjgg9Z+r9errVu3av/+/Wpubtbo0aO1YMECxcbGWmuampq0ceNGffnll7LZbBo/frzmzZungQMHWmu++eYb5efn6+uvv1ZkZKQyMzP1+OOP+8xy+PBhbdmyRXV1dRo+fLjmzJmjBx544HvNAgAA+q8+dSbrypUrSkhI0Pz582+6/+OPP9bu3buVk5Oj3/72txowYIByc3N19epVa83bb7+tqqoqvfrqq3rppZd08uRJvfvuu9b+lpYWLV++XEOHDtWKFSv07LPP6qOPPtK+ffusNadOndIf/vAHTZkyRXl5eRo3bpxWrlypc+fOfa9ZAABA/9WnImvs2LGaNWuWz9mrTl6vV0VFRXryySc1btw4xcfHa/HixWpoaNDnn38uSaqurlZJSYl++ctfKjk5WaNHj1Z2draKi4v17bffSpIOHTokj8ejhQsXasSIEXr44Yf105/+VDt37rS+VlFRkdLT0/Wzn/1MLpdLs2bNUmJiovbs2dPlWQAAQP/WpyLrdmpra+V2u3X//fdb28LCwpSUlKTy8nJJUnl5ucLDw3Xvvfdaa1JTU2Wz2VRRUWGtue+++2S3//+V0rS0NNXU1Kipqclak5qa6vP109LSdPr06S7PAgAA+rc+dU/W7bjdbklSVFSUz/aoqChrn9vtVmRkpM/+4OBgRURE+KyJiYnxWeN0Oq19nWv/2tf5a7PcTFtbm9ra2qzXNptNoaGh1r8BALjb9af3u4CJrLtBYWGhtm3bZr0eNWqU8vLyNGzYMD9O1Ttq/D0AACAg9KdfEAuYyOo829TY2Kjo6Ghre2NjoxISEqw1ly5d8vm89vZ2NTU1WZ/vdDpvONvU+fraNY2NjT5rGhsbffb/tVluZsaMGcrKyrJed9Z8XV2dPB7PLT8PAIC7xYULF/w9Qo/Z7fYunSAJmHuyYmJi5HQ6dfz4cWtbS0uLKioqlJKSIklKSUlRc3OzKisrrTWlpaXyer1KSkqy1pw8edInao4dO6a4uDhFRERYa679Op1rkpOTuzzLzTgcDoWFhVkfnZcKpe9upg/kDwAAusLf71d38j2vT0XW5cuXdfbsWZ09e1bSdzeYnz17VvX19bLZbJo+fbr+9Kc/6YsvvtC5c+e0Zs0aRUdHa9y4cZIkl8ul9PR0vfvuu6qoqNB//dd/aePGjXrooYc0ePBgSdLEiRNlt9u1fv16VVVVqbi4WLt37/Y5wzR9+nR99dVX2rFjh86fP6+tW7fq66+/VmZmpiR1aRYAANC/2bx96DREWVmZli1bdsP2SZMmadGiRdYDQPft26eWlhaNHj1a8+fPV1xcnLW2qalJ+fn5Pg8jzc7OvuXDSAcNGqTMzEw98cQTPl/z8OHD2rx5s+rq6hQbG3vLh5Hebpauqqur87khPhBd+NUCf48AAAgAsSs3+HuEHnM4HF26XNinIqu/IrIAAP1Ff4qsPnW5EAAA4G5BZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhAZAEAABhg9/cA38fWrVu1bds2n21xcXFavXq1JOnq1asqKChQcXGx2tralJaWpgULFsjpdFrr6+vr9d5776msrEwDBw7UpEmTNHv2bAUHB1trysrKVFBQoKqqKg0ZMkRPPfWUMjIyfL7unj17tGPHDrndbsXHxys7O1tJSUmmvnUAABBgAiqyJGnEiBF67bXXrNdBQf9/Mm7Tpk06evSoXnjhBYWFhSk/P1+rVq3Sb37zG0lSR0eH3nzzTTmdTi1fvlwNDQ1as2aNgoODNXv2bElSbW2tVqxYoZ/85CdasmSJSktLtX79ejmdTqWnp0uSiouLVVBQoJycHCUnJ2vXrl3Kzc3V6tWrFRUVded+GAAAoM8KuMuFQUFBcjqd1kdkZKQkqaWlRQcOHNDcuXM1ZswYJSYmauHChTp16pTKy8slSV999ZWqq6u1ZMkSJSQkaOzYsZo5c6b27t0rj8cjSfrkk08UExOj5557Ti6XS5mZmZowYYJ27dplzbBz505NnTpVkydPlsvlUk5OjkJCQnTw4ME7/wMBAAB9UsBF1sWLF/X3f//3Wrx4sd5++23V19dLkiorK9Xe3q7U1FRr7T333KOhQ4dakVVeXq6RI0f6XD5MT09Xa2urqqqqJEmnT5/2OYYkpaWlWcfweDyqrKz0WRMUFKTU1FRrza20tbWppaXF+mhtbbX22Wy2gP4AAKAr/P1+dSff8wLqcmFycrIWLlyouLg4NTQ0aNu2bXr99de1atUqud1u2e12hYeH+3xOVFSU3G63JMntdvsEVuf+zn2d/73+kl9UVJRaW1t19epVNTU1qaOj44bjOJ1O1dTU3Hb+wsJCn3vKRo0apby8PA0bNqyLP4G+6/bfOQAA34mNjfX3CHdMQEXW2LFjrX/Hx8db0XX48GGFhIT4cbKumTFjhrKysqzXnTVcV1dnXa4EAOBuduHCBX+P0GN2u71LJ0gCKrKuFx4erri4OF28eFH333+/PB6Pmpubfc5mNTY2WmednE6nKioqfI7R2Nho7ev8b+e2a9eEhoYqJCREkZGRCgoKss58dbrZWbLrORwOORyOm+7zer1/5bsFACDw9af3u4C7J+taly9f1sWLF+V0OpWYmKjg4GAdP37c2l9TU6P6+nqlpKRIklJSUnTu3DmfiDp27JhCQ0PlcrkkfXdJ8tpjdK7pPIbdbldiYqJKS0ut/R0dHSotLbXWAAAABFRkFRQU6MSJE6qtrdWpU6e0cuVKBQUFaeLEiQoLC9OUKVNUUFCg0tJSVVZWat26dUpJSbHiJy0tTS6XS2vWrNHZs2dVUlKizZs3a9q0adYZpkcffVS1tbV6//33df78ee3du1eHDx/WY489Zs2RlZWl/fv369NPP1V1dbU2bNigK1eu3PAsLQAA0H/ZvAF03m716tU6efKk/vd//1eRkZEaPXq0Zs2apeHDh0v6/4eRfvbZZ/J4PDd9GGldXZ02bNigsrIyDRgwQJMmTdKcOXNueBjppk2bVF1dfduHkW7fvl1ut1sJCQmaN2+ekpOTu/V91dXVqa2trVuf21dc+NUCf48AAAgAsSs3+HuEHnM4HF26JyugIutuRWQBAPqL/hRZAXW5EAAAIFAQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAYQWQAAAAbY/T1AoNuzZ4927Nght9ut+Ph4ZWdnKykpyd9jAQAAP+NMVg8UFxeroKBATz/9tPLy8hQfH6/c3Fw1Njb6ezQAAOBnRFYP7Ny5U1OnTtXkyZPlcrmUk5OjkJAQHTx40N+jAQAAP+NyYTd5PB5VVlbqiSeesLYFBQUpNTVV5eXlN/2ctrY2tbW1Wa9tNptCQ0Nltwf+/4bQhHv9PQIAIAA4HA5/j9BjXX3fDvx3dz+5dOmSOjo65HQ6fbY7nU7V1NTc9HMKCwu1bds26/XDDz+s559/XtHR0SZHvSOG5b7j7xEAAOhTiKw7aMaMGcrKyvLZ1tbWdldUPQBfra2tWrp0qZYuXarQ0FB/jwPAD4isboqMjFRQUJDcbrfPdrfbfcPZrU4Oh4OgAvoJr9erM2fOyOv1+nsUAH7Cje/dZLfblZiYqNLSUmtbR0eHSktLlZKS4sfJAABAX8CZrB7IysrS2rVrlZiYqKSkJBUVFenKlSvKyMjw92gAAMDPiKweeOihh3Tp0iVt3bpVbrdbCQkJevnll295uRBA/+FwOPT0009ziwDQj9m83DAAAADQ67gnCwAAwAAiCwAAwAAiCwAAwAAiCwAAwAB+uxAAetmePXu0Y8cOud1uxcfHKzs7W0lJSf4eC8AdxpksAOhFxcXFKigo0NNPP628vDzFx8crNzdXjY2N/h4NwB1GZAFAL9q5c6emTp2qyZMny+VyKScnRyEhITp48KC/RwNwhxFZANBLPB6PKisrlZqaam0LCgpSamqqysvL/TgZAH8gsgCgl1y6dEkdHR03/NUHp9N5wx+TB3D3I7IAAAAMILIAoJdERkYqKCjohrNWbrebv2kK9ENEFgD0ErvdrsTERJWWllrbOjo6VFpaqpSUFD9OBsAfeE4WAPSirKwsrV27VomJiUpKSlJRUZGuXLmijIwMf48G4A6zeb1er7+HAIC7yZ49e7R9+3a53W4lJCRo3rx5Sk5O9vdYAO4wIgsAAMAA7skCAAAwgMgCAAAwgMgCAAAwgMgCAAAwgMgCAAAwgMgCAAAwgMgCAAAwgMgCAAAwgMgCAAAwgMgCAAAwgMgCAAAwgMgCAAAw4P8A2ZNHjkb6khcAAAAASUVORK5CYII="},"metadata":{}}]},{"cell_type":"code","source":"X = data.drop('Class', axis = 1)\ny=data['Class']","metadata":{"execution":{"iopub.status.busy":"2024-04-27T07:52:39.611933Z","iopub.execute_input":"2024-04-27T07:52:39.612284Z","iopub.status.idle":"2024-04-27T07:52:39.638501Z","shell.execute_reply.started":"2024-04-27T07:52:39.612258Z","shell.execute_reply":"2024-04-27T07:52:39.637406Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-04-27T07:52:40.489125Z","iopub.execute_input":"2024-04-27T07:52:40.489476Z","iopub.status.idle":"2024-04-27T07:52:40.596498Z","shell.execute_reply.started":"2024-04-27T07:52:40.489443Z","shell.execute_reply":"2024-04-27T07:52:40.595575Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2024-04-27T07:52:41.244665Z","iopub.execute_input":"2024-04-27T07:52:41.245329Z","iopub.status.idle":"2024-04-27T07:52:41.329621Z","shell.execute_reply.started":"2024-04-27T07:52:41.245294Z","shell.execute_reply":"2024-04-27T07:52:41.328579Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"import numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-04-27T07:52:41.977604Z","iopub.execute_input":"2024-04-27T07:52:41.978333Z","iopub.status.idle":"2024-04-27T07:52:41.982446Z","shell.execute_reply.started":"2024-04-27T07:52:41.978299Z","shell.execute_reply":"2024-04-27T07:52:41.981324Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\n","metadata":{"execution":{"iopub.status.busy":"2024-04-27T07:52:42.730222Z","iopub.execute_input":"2024-04-27T07:52:42.730582Z","iopub.status.idle":"2024-04-27T07:52:42.984139Z","shell.execute_reply.started":"2024-04-27T07:52:42.730556Z","shell.execute_reply":"2024-04-27T07:52:42.983033Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nclassifier = {\n    \"Logistic Regression\": LogisticRegression(),\n    \"Decision Tree Classifier\": DecisionTreeClassifier(),\n    \"Random Forest Classifier\": RandomForestClassifier(),\n    \"Support Vector Classifier\": SVC(),\n    \"K-Nearest Neighbors Classifier\": KNeighborsClassifier(),\n    \"Gaussian Naive Bayes\": GaussianNB(),\n    \"AdaBoost Classifier\": AdaBoostClassifier(),\n    \"Gradient Boosting Classifier\": GradientBoostingClassifier(),\n    \"Bagging Classifier\": BaggingClassifier(),\n    \"Extra Trees Classifier\": ExtraTreesClassifier(),\n    \"Stochastic Gradient Descent Classifier\": SGDClassifier(),\n    \"Voting Classifier\": VotingClassifier(estimators=[\n        ('lr', LogisticRegression()),\n        ('dt', DecisionTreeClassifier()),\n        ('rf', RandomForestClassifier()),\n        ('svc', SVC()),\n        ('knn', KNeighborsClassifier())\n    ], voting='hard')\n}\n\nfor name, clf in classifier.items():\n    print(f\"\\n=========={name}===========\")\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    \n    # Evaluation Metrics\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred)\n    print(f\"\\n Accuracy: {accuracy}\")\n    print(f\" Precision: {precision}\")\n    print(f\" Recall: {recall}\")\n    print(f\" F1 Score: {f1}\")\n    \n    # Confusion Matrix\n    print(\"\\n Confusion Matrix:\")\n    print(confusion_matrix(y_test, y_pred))\n    \n    # Classification Report\n    print(\"\\n Classification Report:\")\n    print(classification_report(y_test, y_pred))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-27T07:52:43.909147Z","iopub.execute_input":"2024-04-27T07:52:43.909809Z","iopub.status.idle":"2024-04-27T08:14:28.940648Z","shell.execute_reply.started":"2024-04-27T07:52:43.909771Z","shell.execute_reply":"2024-04-27T08:14:28.939647Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"\n==========Logistic Regression===========\n\n Accuracy: 0.9992200678359603\n Precision: 0.8870967741935484\n Recall: 0.6043956043956044\n F1 Score: 0.718954248366013\n\n Confusion Matrix:\n[[55035     7]\n [   36    55]]\n\n Classification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00     55042\n           1       0.89      0.60      0.72        91\n\n    accuracy                           1.00     55133\n   macro avg       0.94      0.80      0.86     55133\nweighted avg       1.00      1.00      1.00     55133\n\n\n==========Decision Tree Classifier===========\n\n Accuracy: 0.9989298605191084\n Precision: 0.6666666666666666\n Recall: 0.7032967032967034\n F1 Score: 0.6844919786096256\n\n Confusion Matrix:\n[[55010    32]\n [   27    64]]\n\n Classification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00     55042\n           1       0.67      0.70      0.68        91\n\n    accuracy                           1.00     55133\n   macro avg       0.83      0.85      0.84     55133\nweighted avg       1.00      1.00      1.00     55133\n\n\n==========Random Forest Classifier===========\n\n Accuracy: 0.9994558612809026\n Precision: 0.9178082191780822\n Recall: 0.7362637362637363\n F1 Score: 0.8170731707317073\n\n Confusion Matrix:\n[[55036     6]\n [   24    67]]\n\n Classification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00     55042\n           1       0.92      0.74      0.82        91\n\n    accuracy                           1.00     55133\n   macro avg       0.96      0.87      0.91     55133\nweighted avg       1.00      1.00      1.00     55133\n\n\n==========Support Vector Classifier===========\n\n Accuracy: 0.9993288955797798\n Precision: 0.9354838709677419\n Recall: 0.6373626373626373\n F1 Score: 0.7581699346405227\n\n Confusion Matrix:\n[[55038     4]\n [   33    58]]\n\n Classification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00     55042\n           1       0.94      0.64      0.76        91\n\n    accuracy                           1.00     55133\n   macro avg       0.97      0.82      0.88     55133\nweighted avg       1.00      1.00      1.00     55133\n\n\n==========K-Nearest Neighbors Classifier===========\n\n Accuracy: 0.999419585366296\n Precision: 0.8831168831168831\n Recall: 0.7472527472527473\n F1 Score: 0.8095238095238096\n\n Confusion Matrix:\n[[55033     9]\n [   23    68]]\n\n Classification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00     55042\n           1       0.88      0.75      0.81        91\n\n    accuracy                           1.00     55133\n   macro avg       0.94      0.87      0.90     55133\nweighted avg       1.00      1.00      1.00     55133\n\n\n==========Gaussian Naive Bayes===========\n\n Accuracy: 0.9781618994068888\n Precision: 0.057279236276849645\n Recall: 0.7912087912087912\n F1 Score: 0.10682492581602375\n\n Confusion Matrix:\n[[53857  1185]\n [   19    72]]\n\n Classification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      0.98      0.99     55042\n           1       0.06      0.79      0.11        91\n\n    accuracy                           0.98     55133\n   macro avg       0.53      0.88      0.55     55133\nweighted avg       1.00      0.98      0.99     55133\n\n\n==========AdaBoost Classifier===========\n\n Accuracy: 0.9991112400921408\n Precision: 0.75\n Recall: 0.6923076923076923\n F1 Score: 0.7199999999999999\n\n Confusion Matrix:\n[[55021    21]\n [   28    63]]\n\n Classification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00     55042\n           1       0.75      0.69      0.72        91\n\n    accuracy                           1.00     55133\n   macro avg       0.87      0.85      0.86     55133\nweighted avg       1.00      1.00      1.00     55133\n\n\n==========Gradient Boosting Classifier===========\n\n Accuracy: 0.9986033772876499\n Precision: 0.71875\n Recall: 0.25274725274725274\n F1 Score: 0.37398373983739835\n\n Confusion Matrix:\n[[55033     9]\n [   68    23]]\n\n Classification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00     55042\n           1       0.72      0.25      0.37        91\n\n    accuracy                           1.00     55133\n   macro avg       0.86      0.63      0.69     55133\nweighted avg       1.00      1.00      1.00     55133\n\n\n==========Bagging Classifier===========\n\n Accuracy: 0.9994558612809026\n Precision: 0.8961038961038961\n Recall: 0.7582417582417582\n F1 Score: 0.8214285714285714\n\n Confusion Matrix:\n[[55034     8]\n [   22    69]]\n\n Classification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00     55042\n           1       0.90      0.76      0.82        91\n\n    accuracy                           1.00     55133\n   macro avg       0.95      0.88      0.91     55133\nweighted avg       1.00      1.00      1.00     55133\n\n\n==========Extra Trees Classifier===========\n\n Accuracy: 0.9994739992382058\n Precision: 0.9305555555555556\n Recall: 0.7362637362637363\n F1 Score: 0.8220858895705522\n\n Confusion Matrix:\n[[55037     5]\n [   24    67]]\n\n Classification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00     55042\n           1       0.93      0.74      0.82        91\n\n    accuracy                           1.00     55133\n   macro avg       0.97      0.87      0.91     55133\nweighted avg       1.00      1.00      1.00     55133\n\n\n==========Stochastic Gradient Descent Classifier===========\n\n Accuracy: 0.9990386882629279\n Precision: 0.8064516129032258\n Recall: 0.5494505494505495\n F1 Score: 0.6535947712418301\n\n Confusion Matrix:\n[[55030    12]\n [   41    50]]\n\n Classification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00     55042\n           1       0.81      0.55      0.65        91\n\n    accuracy                           1.00     55133\n   macro avg       0.90      0.77      0.83     55133\nweighted avg       1.00      1.00      1.00     55133\n\n\n==========Voting Classifier===========\n\n Accuracy: 0.9994739992382058\n Precision: 0.9305555555555556\n Recall: 0.7362637362637363\n F1 Score: 0.8220858895705522\n\n Confusion Matrix:\n[[55037     5]\n [   24    67]]\n\n Classification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00     55042\n           1       0.93      0.74      0.82        91\n\n    accuracy                           1.00     55133\n   macro avg       0.97      0.87      0.91     55133\nweighted avg       1.00      1.00      1.00     55133\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Undersampling","metadata":{},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"normal = data[data['Class']==0]\nfraud = data[data['Class']==1]","metadata":{},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"normal.shape","metadata":{},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":["(275190, 30)"]},"metadata":{}}]},{"cell_type":"code","source":"fraud.shape","metadata":{},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":["(473, 30)"]},"metadata":{}}]},{"cell_type":"code","source":"normal_sample = normal.sample(n=473)","metadata":{},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"normal_sample.shape","metadata":{},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":["(473, 30)"]},"metadata":{}}]},{"cell_type":"code","source":"new_data = pd.concat([normal_sample,fraud], ignore_index=True)","metadata":{},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"new_data.head()","metadata":{},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>V1</th>\n","      <th>V2</th>\n","      <th>V3</th>\n","      <th>V4</th>\n","      <th>V5</th>\n","      <th>V6</th>\n","      <th>V7</th>\n","      <th>V8</th>\n","      <th>V9</th>\n","      <th>V10</th>\n","      <th>V11</th>\n","      <th>V12</th>\n","      <th>V13</th>\n","      <th>V14</th>\n","      <th>V15</th>\n","      <th>V16</th>\n","      <th>V17</th>\n","      <th>V18</th>\n","      <th>V19</th>\n","      <th>V20</th>\n","      <th>V21</th>\n","      <th>V22</th>\n","      <th>V23</th>\n","      <th>V24</th>\n","      <th>V25</th>\n","      <th>V26</th>\n","      <th>V27</th>\n","      <th>V28</th>\n","      <th>Amount</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.390664</td>\n","      <td>1.973736</td>\n","      <td>-1.945026</td>\n","      <td>1.789083</td>\n","      <td>0.647230</td>\n","      <td>-1.744105</td>\n","      <td>0.592489</td>\n","      <td>0.198540</td>\n","      <td>-0.687046</td>\n","      <td>-1.482981</td>\n","      <td>1.416687</td>\n","      <td>0.234829</td>\n","      <td>0.625176</td>\n","      <td>-3.322279</td>\n","      <td>1.161863</td>\n","      <td>0.471132</td>\n","      <td>3.416011</td>\n","      <td>0.822989</td>\n","      <td>-0.981826</td>\n","      <td>-0.008713</td>\n","      <td>-0.032939</td>\n","      <td>0.106399</td>\n","      <td>0.221280</td>\n","      <td>0.282636</td>\n","      <td>-0.551100</td>\n","      <td>-0.404796</td>\n","      <td>0.154992</td>\n","      <td>-0.043364</td>\n","      <td>-0.346073</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.643022</td>\n","      <td>-1.571045</td>\n","      <td>0.387174</td>\n","      <td>0.346115</td>\n","      <td>1.384183</td>\n","      <td>0.010196</td>\n","      <td>-0.806426</td>\n","      <td>0.443410</td>\n","      <td>1.084875</td>\n","      <td>-0.531256</td>\n","      <td>-0.261706</td>\n","      <td>1.138270</td>\n","      <td>0.018514</td>\n","      <td>-0.271938</td>\n","      <td>-1.332018</td>\n","      <td>-0.457547</td>\n","      <td>-0.335835</td>\n","      <td>0.459164</td>\n","      <td>1.575998</td>\n","      <td>0.474020</td>\n","      <td>-0.091317</td>\n","      <td>-0.560819</td>\n","      <td>0.679125</td>\n","      <td>0.028114</td>\n","      <td>-0.732934</td>\n","      <td>-0.987867</td>\n","      <td>0.058414</td>\n","      <td>0.052270</td>\n","      <td>0.013755</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-2.549290</td>\n","      <td>1.528338</td>\n","      <td>-1.206697</td>\n","      <td>-1.737109</td>\n","      <td>1.953693</td>\n","      <td>-0.176467</td>\n","      <td>1.864754</td>\n","      <td>-2.206843</td>\n","      <td>1.072224</td>\n","      <td>2.215222</td>\n","      <td>0.359018</td>\n","      <td>-0.491519</td>\n","      <td>-1.041874</td>\n","      <td>-0.274162</td>\n","      <td>-0.267963</td>\n","      <td>-0.595064</td>\n","      <td>-1.289545</td>\n","      <td>0.308163</td>\n","      <td>0.721806</td>\n","      <td>-0.458287</td>\n","      <td>0.856566</td>\n","      <td>0.416235</td>\n","      <td>-0.394658</td>\n","      <td>-0.127826</td>\n","      <td>0.192799</td>\n","      <td>-0.105903</td>\n","      <td>-2.781880</td>\n","      <td>-0.548808</td>\n","      <td>-0.322964</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.993656</td>\n","      <td>0.124010</td>\n","      <td>-1.549448</td>\n","      <td>1.300218</td>\n","      <td>0.347976</td>\n","      <td>-0.903320</td>\n","      <td>0.455070</td>\n","      <td>-0.210637</td>\n","      <td>0.111435</td>\n","      <td>0.464175</td>\n","      <td>0.605472</td>\n","      <td>0.428546</td>\n","      <td>-1.514553</td>\n","      <td>0.962728</td>\n","      <td>-1.100020</td>\n","      <td>-0.514634</td>\n","      <td>-0.281200</td>\n","      <td>-0.053132</td>\n","      <td>0.044279</td>\n","      <td>-0.382663</td>\n","      <td>0.089356</td>\n","      <td>0.412068</td>\n","      <td>0.016659</td>\n","      <td>-0.008406</td>\n","      <td>0.380561</td>\n","      <td>-0.507496</td>\n","      <td>-0.024450</td>\n","      <td>-0.075138</td>\n","      <td>-0.349231</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.209858</td>\n","      <td>0.173233</td>\n","      <td>1.232594</td>\n","      <td>3.246544</td>\n","      <td>3.453106</td>\n","      <td>-1.080207</td>\n","      <td>-4.346397</td>\n","      <td>-1.262771</td>\n","      <td>-0.039137</td>\n","      <td>1.726905</td>\n","      <td>-1.759217</td>\n","      <td>0.216746</td>\n","      <td>-0.016093</td>\n","      <td>0.046866</td>\n","      <td>-0.922259</td>\n","      <td>1.270735</td>\n","      <td>-0.909432</td>\n","      <td>-0.171599</td>\n","      <td>-2.303246</td>\n","      <td>-0.844501</td>\n","      <td>1.786023</td>\n","      <td>-0.640560</td>\n","      <td>-5.591452</td>\n","      <td>0.842909</td>\n","      <td>-1.657128</td>\n","      <td>-0.234552</td>\n","      <td>0.651888</td>\n","      <td>0.557532</td>\n","      <td>-0.232247</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         V1        V2        V3        V4        V5        V6        V7  \\\n","0  0.390664  1.973736 -1.945026  1.789083  0.647230 -1.744105  0.592489   \n","1 -0.643022 -1.571045  0.387174  0.346115  1.384183  0.010196 -0.806426   \n","2 -2.549290  1.528338 -1.206697 -1.737109  1.953693 -0.176467  1.864754   \n","3  1.993656  0.124010 -1.549448  1.300218  0.347976 -0.903320  0.455070   \n","4 -0.209858  0.173233  1.232594  3.246544  3.453106 -1.080207 -4.346397   \n","\n","         V8        V9       V10       V11       V12       V13       V14  \\\n","0  0.198540 -0.687046 -1.482981  1.416687  0.234829  0.625176 -3.322279   \n","1  0.443410  1.084875 -0.531256 -0.261706  1.138270  0.018514 -0.271938   \n","2 -2.206843  1.072224  2.215222  0.359018 -0.491519 -1.041874 -0.274162   \n","3 -0.210637  0.111435  0.464175  0.605472  0.428546 -1.514553  0.962728   \n","4 -1.262771 -0.039137  1.726905 -1.759217  0.216746 -0.016093  0.046866   \n","\n","        V15       V16       V17       V18       V19       V20       V21  \\\n","0  1.161863  0.471132  3.416011  0.822989 -0.981826 -0.008713 -0.032939   \n","1 -1.332018 -0.457547 -0.335835  0.459164  1.575998  0.474020 -0.091317   \n","2 -0.267963 -0.595064 -1.289545  0.308163  0.721806 -0.458287  0.856566   \n","3 -1.100020 -0.514634 -0.281200 -0.053132  0.044279 -0.382663  0.089356   \n","4 -0.922259  1.270735 -0.909432 -0.171599 -2.303246 -0.844501  1.786023   \n","\n","        V22       V23       V24       V25       V26       V27       V28  \\\n","0  0.106399  0.221280  0.282636 -0.551100 -0.404796  0.154992 -0.043364   \n","1 -0.560819  0.679125  0.028114 -0.732934 -0.987867  0.058414  0.052270   \n","2  0.416235 -0.394658 -0.127826  0.192799 -0.105903 -2.781880 -0.548808   \n","3  0.412068  0.016659 -0.008406  0.380561 -0.507496 -0.024450 -0.075138   \n","4 -0.640560 -5.591452  0.842909 -1.657128 -0.234552  0.651888  0.557532   \n","\n","     Amount  Class  \n","0 -0.346073      0  \n","1  0.013755      0  \n","2 -0.322964      0  \n","3 -0.349231      0  \n","4 -0.232247      0  "]},"metadata":{}}]},{"cell_type":"code","source":"new_data['Class'].value_counts()","metadata":{},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":["0    473\n","1    473\n","Name: Class, dtype: int64"]},"metadata":{}}]},{"cell_type":"code","source":"X = new_data.drop('Class', axis = 1)\ny= new_data['Class']","metadata":{},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","metadata":{},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"classifier = {\n    \"Logistic Regression\": LogisticRegression(),\n    \"Decision Tree Classifier\": DecisionTreeClassifier()\n}\n\nfor name, clf in classifier.items():\n    print(f\"\\n=========={name}===========\")\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    print(f\"\\n Accuaracy: {accuracy_score(y_test, y_pred)}\")\n    print(f\"\\n Precision: {precision_score(y_test, y_pred)}\")\n    print(f\"\\n Recall: {recall_score(y_test, y_pred)}\")\n    print(f\"\\n F1 Score: {f1_score(y_test, y_pred)}\")","metadata":{},"execution_count":42,"outputs":[{"name":"stdout","output_type":"stream","text":"\n\n==========Logistic Regression===========\n\n\n\n Accuaracy: 0.9263157894736842\n\n\n\n Precision: 0.9489795918367347\n\n\n\n Recall: 0.9117647058823529\n\n\n\n F1 Score: 0.9300000000000002\n\n\n\n==========Decision Tree Classifier===========\n\n\n\n Accuaracy: 0.8842105263157894\n\n\n\n Precision: 0.8921568627450981\n\n\n\n Recall: 0.8921568627450981\n\n\n\n F1 Score: 0.8921568627450981\n"}]},{"cell_type":"code","source":"# OVERSAMPLING","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = data.drop('Class', axis = 1)\ny= data['Class']","metadata":{},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":["(275663, 29)"]},"metadata":{}}]},{"cell_type":"code","source":"y.shape","metadata":{},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":["(275663,)"]},"metadata":{}}]},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE","metadata":{},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"X_res, y_res = SMOTE().fit_resample(X,y)","metadata":{},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"y_res.value_counts()","metadata":{},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":["0    275190\n","1    275190\n","Name: Class, dtype: int64"]},"metadata":{}}]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size = 0.2, random_state = 42)","metadata":{},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"classifier = {\n    \"Logistic Regression\": LogisticRegression(),\n    \"Decision Tree Classifier\": DecisionTreeClassifier()\n}\n\nfor name, clf in classifier.items():\n    print(f\"\\n=========={name}===========\")\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    print(f\"\\n Accuaracy: {accuracy_score(y_test, y_pred)}\")\n    print(f\"\\n Precision: {precision_score(y_test, y_pred)}\")\n    print(f\"\\n Recall: {recall_score(y_test, y_pred)}\")\n    print(f\"\\n F1 Score: {f1_score(y_test, y_pred)}\")","metadata":{},"execution_count":56,"outputs":[{"name":"stdout","output_type":"stream","text":"\n\n==========Logistic Regression===========\n\n\n\n Accuaracy: 0.9438115483847523\n\n\n\n Precision: 0.9729326513213982\n\n\n\n Recall: 0.9129502027162155\n\n\n\n F1 Score: 0.9419875252075225\n\n\n\n==========Decision Tree Classifier===========\n\n\n\n Accuaracy: 0.9982012427777173\n\n\n\n Precision: 0.9976391537274131\n\n\n\n Recall: 0.9987637037979746\n\n\n\n F1 Score: 0.9982011120398299\n"}]},{"cell_type":"code","source":"dtc = DecisionTreeClassifier()\ndtc.fit(X_res, y_res)","metadata":{},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/html":["<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"],"text/plain":["DecisionTreeClassifier()"]},"metadata":{}}]},{"cell_type":"code","source":"import joblib","metadata":{},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"joblib.dump(dtc, \"credit_card_model.pkl\")","metadata":{},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":["['credit_card_model.pkl']"]},"metadata":{}}]},{"cell_type":"code","source":"model = joblib.load(\"credit_card_model.pkl\")","metadata":{},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"pred = model.predict([[-1.3598071336738,-0.0727811733098497,2.53634673796914,1.37815522427443,-0.338320769942518,0.462387777762292,0.239598554061257,0.0986979012610507,0.363786969611213,0.0907941719789316,-0.551599533260813,-0.617800855762348,-0.991389847235408,-0.311169353699879,1.46817697209427,-0.470400525259478,0.207971241929242,0.0257905801985591,0.403992960255733,0.251412098239705,-0.018306777944153,0.277837575558899,-0.110473910188767,0.0669280749146731,0.128539358273528,-0.189114843888824,0.133558376740387,-0.0210530534538215,149.62]])","metadata":{},"execution_count":61,"outputs":[{"name":"stderr","output_type":"stream","text":"d:\\python38\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n\n  warnings.warn(\n"}]},{"cell_type":"code","source":"pred[0]","metadata":{},"execution_count":62,"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{}}]},{"cell_type":"code","source":"if pred[0] == 0:\n    print(\"Normal Transcation\")\nelse:\n    print(\"Fraud Transcation\")","metadata":{},"execution_count":63,"outputs":[{"name":"stdout","output_type":"stream","text":"Normal Transcation\n"}]},{"cell_type":"code","source":"# Flask, Streamlit-> Homework","metadata":{},"execution_count":null,"outputs":[]}]}